{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae11ecc3",
   "metadata": {},
   "source": [
    "## CAIRN Backblaze B2 Folder Upload Script\n",
    "\n",
    "This script uploads all files from a specified local folder (e.g., on your Desktop)\n",
    "to CAIRN's Backblaze B2 bucket and lists the uploaded files.\n",
    "\n",
    "1.  **Install Libraries:**\n",
    "    Open your terminal or command prompt and run:\n",
    "    pip install python-dotenv b2sdk\n",
    "\n",
    "2.  **Create `.env` File:**\n",
    "    In the SAME directory where you save this Python script, create a file named exactly `.env` (note the leading dot). Open it in a text editor and add your Backblaze B2 Application Key ID, Application Key, and the exact name of the bucket you want to upload to:\n",
    "\n",
    "    B2_ACCESS_KEY_ID=YOUR_APPLICATION_KEY_ID  \n",
    "    B2_SECRET_ACCESS_KEY=YOUR_APPLICATION_KEY  \n",
    "    B2_BUCKET_NAME=your-exact-b2-bucket-name  \n",
    "\n",
    "    Replace the placeholders with your actual credentials and bucket name.\n",
    "\n",
    "3.  **Set the Local Folder Path:**\n",
    "    Find the line below that starts with `LOCAL_FOLDER_PATH = ...`  \n",
    "    Modify the path to point to the *exact* folder on your computer that contains the files you want to upload.  Utilize an LLM For clarity if confusion.\n",
    "\n",
    "\n",
    "4.  **Set B2 Folder Prefix (Optional):**\n",
    "    If you want the files to appear inside a specific 'folder' within your B2 bucket, change `B2_FOLDER_PREFIX`.   \n",
    "    For example: B2_FOLDER_PREFIX = \"project_files/january/\"\n",
    "    Leave as \"\" to upload to the bucket's root.\n",
    "\n",
    "5.  **Run the Script:**\n",
    "    Open your terminal or command prompt, navigate to the directory where you saved this script and the `.env` file, and run: python your_script_name.py or run as a juypter notebook\n",
    "\n",
    "6.  **Check Output:**\n",
    "    The script will log its progress in the terminal, including connection status, which files it's uploading, and a final summary listing thesuccessfully uploaded files (with their names as they appear in B2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3540063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from b2sdk.v2 import B2Api, InMemoryAccountInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "becf4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env & set configs\n",
    "# --- Load Environment Variables from .env file ---\n",
    "load_dotenv()\n",
    "# ---\n",
    "\n",
    "# --- Basic Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# ---! Configuration: YOU MUST EDIT THESE TWO LINES !---\n",
    "\n",
    "# 1. LOCAL_FOLDER_PATH:\n",
    "#    Set the FULL path to the LOCAL FOLDER on your computer whose contents\n",
    "#    you want to upload.\n",
    "#    Example (Windows): LOCAL_FOLDER_PATH = Path(r\"C:\\Users\\YourUser\\Documents\\UploadMe\")\n",
    "#    Example (Mac/Linux): LOCAL_FOLDER_PATH = Path(\"/home/youruser/data/source_files\")\n",
    "#LOCAL_FOLDER_PATH = Path(r\"C:\\path\\to\\your\\local\\FOLDER\") # <--- CHANGE THIS\n",
    "\n",
    "LOCAL_FOLDER_PATH = Path(r\"C:\\Users\\shugs\\OneDrive\\Desktop\\Cairn (W)\\CAIRN_PDF_Testing_3.2025\\PUC RuleMaking\") # <--- CHANGE THIS\n",
    "\n",
    "\n",
    "# 2. B2_FOLDER_PREFIX:\n",
    "#    Set the 'virtual folder' path within your B2 bucket where files should be\n",
    "#    uploaded. Leave as \"\" to upload to the bucket's root.\n",
    "#    IMPORTANT: If you use a prefix, end it with a forward slash '/'\n",
    "#    Example (Root): B2_FOLDER_PREFIX = \"\"\n",
    "#    Example (Folder): B2_FOLDER_PREFIX = \"project_files/images/\"\n",
    "#B2_FOLDER_PREFIX = \"\" # <--- CHANGE THIS (e.g., \"my_uploads/\" or \"\")\n",
    "\n",
    "# Use upload_testing_folder as default \n",
    "B2_FOLDER_PREFIX = \"upload_testing_folder/\" \n",
    "\n",
    "# --- End of Configuration ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0053bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 00:09:42,947 - INFO - === B2 Folder Sync Script (.env, skip existing, detailed report) Starting ===\n",
      "2025-04-14 00:09:42,947 - INFO - Starting B2 sync process for local folder: C:\\Users\\shugs\\OneDrive\\Desktop\\Cairn (W)\\CAIRN_PDF_Testing_3.2025\\PUC RuleMaking\n",
      "2025-04-14 00:09:42,948 - INFO - Target B2 prefix: 'upload_testing_folder/'\n",
      "2025-04-14 00:09:42,949 - INFO - Local folder confirmed: C:\\Users\\shugs\\OneDrive\\Desktop\\Cairn (W)\\CAIRN_PDF_Testing_3.2025\\PUC RuleMaking\n",
      "2025-04-14 00:09:42,949 - INFO - B2 credentials loaded successfully from .env file.\n",
      "2025-04-14 00:09:42,950 - INFO - Initializing B2 API connection...\n",
      "2025-04-14 00:09:42,950 - INFO - Authorizing B2 account...\n",
      "2025-04-14 00:09:43,071 - INFO - Successfully authorized B2 account.\n",
      "2025-04-14 00:09:43,071 - INFO - Connecting to bucket: CAIRN-Test...\n",
      "2025-04-14 00:09:43,233 - INFO - Successfully connected to bucket: CAIRN-Test\n",
      "2025-04-14 00:09:43,233 - INFO - Checking for existing files in B2 bucket 'CAIRN-Test' under prefix 'upload_testing_folder/'...\n",
      "2025-04-14 00:09:43,287 - INFO - Found 1 existing files in B2 target location.\n",
      "2025-04-14 00:09:43,288 - INFO - Scanning local folder for files: C:\\Users\\shugs\\OneDrive\\Desktop\\Cairn (W)\\CAIRN_PDF_Testing_3.2025\\PUC RuleMaking\n",
      "2025-04-14 00:09:43,289 - INFO - Uploading: 'Avista_Electric_IRP_2025.pdf' to B2 as 'upload_testing_folder/Avista_Electric_IRP_2025.pdf'...\n",
      "2025-04-14 00:09:47,750 - INFO - Uploading: 'Avista_Gas_IRP_2025.pdf' to B2 as 'upload_testing_folder/Avista_Gas_IRP_2025.pdf'...\n",
      "2025-04-14 00:09:56,129 - INFO - Uploading: 'CAISO_RootCauseAnalysis_HeatWave_01.13.2021.pdf' to B2 as 'upload_testing_folder/CAISO_RootCauseAnalysis_HeatWave_01.13.2021.pdf'...\n",
      "2025-04-14 00:09:57,913 - INFO - Uploading: 'Columba_Research_ClimateRisk_UtilityPlanning_2020.pdf' to B2 as 'upload_testing_folder/Columba_Research_ClimateRisk_UtilityPlanning_2020.pdf'...\n",
      "2025-04-14 00:10:00,389 - INFO - Uploading: 'CUTC_D20_08_046_EnergyUtility_ClimateChange_Assessment_08.27.2020.PDF' to B2 as 'upload_testing_folder/CUTC_D20_08_046_EnergyUtility_ClimateChange_Assessment_08.27.2020.PDF'...\n",
      "2025-04-14 00:10:03,106 - INFO - Uploading: 'FEC_ExtremeWeather_Vuln_Assessment_E-2-RM22-16-000_06.15.2023.pdf' to B2 as 'upload_testing_folder/FEC_ExtremeWeather_Vuln_Assessment_E-2-RM22-16-000_06.15.2023.pdf'...\n",
      "2025-04-14 00:10:03,640 - INFO - Uploading: 'NARUC_SEIN_Resilient_DER_Review_of_State_Policies_2020.pdf' to B2 as 'upload_testing_folder/NARUC_SEIN_Resilient_DER_Review_of_State_Policies_2020.pdf'...\n",
      "2025-04-14 00:10:05,001 - INFO - Uploading: 'NYC_ClimateImpactAssessment_Energy_2023.pdf' to B2 as 'upload_testing_folder/NYC_ClimateImpactAssessment_Energy_2023.pdf'...\n",
      "2025-04-14 00:10:06,202 - INFO - Uploading: 'P&GE_ClimateAdaption_Vuln_Assessment_2024.pdf' to B2 as 'upload_testing_folder/P&GE_ClimateAdaption_Vuln_Assessment_2024.pdf'...\n",
      "2025-04-14 00:10:56,082 - INFO - Uploading: 'P&GE_IRP_2023_11.01.2022.pdf' to B2 as 'upload_testing_folder/P&GE_IRP_2023_11.01.2022.pdf'...\n",
      "2025-04-14 00:10:57,817 - INFO - Uploading: 'PacificCorp_IRP_Volume1_2025_03.31.2025.pdf' to B2 as 'upload_testing_folder/PacificCorp_IRP_Volume1_2025_03.31.2025.pdf'...\n",
      "2025-04-14 00:11:06,453 - INFO - Uploading: 'PacificCorp_IRP_Volume2_2025_03.31.2025.pdf' to B2 as 'upload_testing_folder/PacificCorp_IRP_Volume2_2025_03.31.2025.pdf'...\n",
      "2025-04-14 00:11:17,402 - INFO - Uploading: 'PGE_IRP_CleanEnergyPlan_2023_06.30.2023.pdf' to B2 as 'upload_testing_folder/PGE_IRP_CleanEnergyPlan_2023_06.30.2023.pdf'...\n",
      "2025-04-14 00:11:27,480 - INFO - Uploading: 'PNNL_Policy_OR_Resilience_CleanEnergy_09.2022.pdf' to B2 as 'upload_testing_folder/PNNL_Policy_OR_Resilience_CleanEnergy_09.2022.pdf'...\n",
      "2025-04-14 00:11:31,665 - INFO - Uploading: 'PSE_GeneralRateCase_FinalOrder_07_09_1.15.25.pdf' to B2 as 'upload_testing_folder/PSE_GeneralRateCase_FinalOrder_07_09_1.15.25.pdf'...\n",
      "2025-04-14 00:11:32,846 - INFO - Uploading: 'PSE_IRP_ElectricAppendicies_3.31.2025.pdf' to B2 as 'upload_testing_folder/PSE_IRP_ElectricAppendicies_3.31.2025.pdf'...\n",
      "2025-04-14 00:11:39,342 - INFO - Uploading: 'PSE_IRP_ElectricChapters_3.31.2025.pdf' to B2 as 'upload_testing_folder/PSE_IRP_ElectricChapters_3.31.2025.pdf'...\n",
      "2025-04-14 00:11:42,190 - INFO - Uploading: 'PSE_IRP_GasAppendicies_3.31.2025.pdf' to B2 as 'upload_testing_folder/PSE_IRP_GasAppendicies_3.31.2025.pdf'...\n",
      "2025-04-14 00:11:46,636 - INFO - Uploading: 'PSE_IRP_GasChapters_3.31.2025.pdf' to B2 as 'upload_testing_folder/PSE_IRP_GasChapters_3.31.2025.pdf'...\n",
      "2025-04-14 00:11:49,656 - INFO - Uploading: 'SanDiegoGasElectric_IRP_2022_05.07_2020.pdf' to B2 as 'upload_testing_folder/SanDiegoGasElectric_IRP_2022_05.07_2020.pdf'...\n",
      "2025-04-14 00:11:57,400 - INFO - Uploading: 'State_Cali_ExtremeHeat_Resilience_2022.pdf' to B2 as 'upload_testing_folder/State_Cali_ExtremeHeat_Resilience_2022.pdf'...\n",
      "2025-04-14 00:12:00,745 - INFO - ==================================================\n",
      "2025-04-14 00:12:00,747 - INFO -               Sync Process Summary Report\n",
      "2025-04-14 00:12:00,747 - INFO - ==================================================\n",
      "2025-04-14 00:12:00,747 - INFO - Local Source Folder: C:\\Users\\shugs\\OneDrive\\Desktop\\Cairn (W)\\CAIRN_PDF_Testing_3.2025\\PUC RuleMaking\n",
      "2025-04-14 00:12:00,747 - INFO - Target B2 Bucket: CAIRN-Test\n",
      "2025-04-14 00:12:00,748 - INFO - Target B2 Prefix: 'upload_testing_folder/'\n",
      "2025-04-14 00:12:00,749 - INFO - \n",
      "Total Local Files Processed: 21\n",
      "2025-04-14 00:12:00,750 - INFO - --------------------------------------------------\n",
      "2025-04-14 00:12:00,750 - INFO - Files Uploaded Successfully (21):\n",
      "2025-04-14 00:12:00,750 - INFO -   - Avista_Electric_IRP_2025.pdf\n",
      "2025-04-14 00:12:00,750 - INFO -   - Avista_Gas_IRP_2025.pdf\n",
      "2025-04-14 00:12:00,751 - INFO -   - CAISO_RootCauseAnalysis_HeatWave_01.13.2021.pdf\n",
      "2025-04-14 00:12:00,751 - INFO -   - CUTC_D20_08_046_EnergyUtility_ClimateChange_Assessment_08.27.2020.PDF\n",
      "2025-04-14 00:12:00,751 - INFO -   - Columba_Research_ClimateRisk_UtilityPlanning_2020.pdf\n",
      "2025-04-14 00:12:00,752 - INFO -   - FEC_ExtremeWeather_Vuln_Assessment_E-2-RM22-16-000_06.15.2023.pdf\n",
      "2025-04-14 00:12:00,752 - INFO -   - NARUC_SEIN_Resilient_DER_Review_of_State_Policies_2020.pdf\n",
      "2025-04-14 00:12:00,752 - INFO -   - NYC_ClimateImpactAssessment_Energy_2023.pdf\n",
      "2025-04-14 00:12:00,754 - INFO -   - P&GE_ClimateAdaption_Vuln_Assessment_2024.pdf\n",
      "2025-04-14 00:12:00,754 - INFO -   - P&GE_IRP_2023_11.01.2022.pdf\n",
      "2025-04-14 00:12:00,755 - INFO -   - PGE_IRP_CleanEnergyPlan_2023_06.30.2023.pdf\n",
      "2025-04-14 00:12:00,755 - INFO -   - PNNL_Policy_OR_Resilience_CleanEnergy_09.2022.pdf\n",
      "2025-04-14 00:12:00,755 - INFO -   - PSE_GeneralRateCase_FinalOrder_07_09_1.15.25.pdf\n",
      "2025-04-14 00:12:00,756 - INFO -   - PSE_IRP_ElectricAppendicies_3.31.2025.pdf\n",
      "2025-04-14 00:12:00,756 - INFO -   - PSE_IRP_ElectricChapters_3.31.2025.pdf\n",
      "2025-04-14 00:12:00,756 - INFO -   - PSE_IRP_GasAppendicies_3.31.2025.pdf\n",
      "2025-04-14 00:12:00,757 - INFO -   - PSE_IRP_GasChapters_3.31.2025.pdf\n",
      "2025-04-14 00:12:00,757 - INFO -   - PacificCorp_IRP_Volume1_2025_03.31.2025.pdf\n",
      "2025-04-14 00:12:00,757 - INFO -   - PacificCorp_IRP_Volume2_2025_03.31.2025.pdf\n",
      "2025-04-14 00:12:00,757 - INFO -   - SanDiegoGasElectric_IRP_2022_05.07_2020.pdf\n",
      "2025-04-14 00:12:00,758 - INFO -   - State_Cali_ExtremeHeat_Resilience_2022.pdf\n",
      "2025-04-14 00:12:00,758 - INFO - --------------------------------------------------\n",
      "2025-04-14 00:12:00,758 - INFO - Files Skipped - Already Exist in B2 (0):\n",
      "2025-04-14 00:12:00,760 - INFO -   (None)\n",
      "2025-04-14 00:12:00,760 - INFO - --------------------------------------------------\n",
      "2025-04-14 00:12:00,760 - INFO - Files Failed to Upload (0):\n",
      "2025-04-14 00:12:00,761 - INFO -   (None)\n",
      "2025-04-14 00:12:00,761 - INFO - ==================================================\n",
      "2025-04-14 00:12:00,762 - INFO - Script finished successfully.\n",
      "2025-04-14 00:12:00,762 - INFO - === Script Execution Complete ===\n"
     ]
    }
   ],
   "source": [
    "def sync_folder_to_b2(local_folder_path, b2_folder_prefix):\n",
    "    \"\"\"\n",
    "    Uploads files from a local folder to a B2 bucket, skipping files\n",
    "    that already exist. Provides a detailed report of actions taken.\n",
    "\n",
    "    Args:\n",
    "        local_folder_path (Path): Path object for the local folder.\n",
    "        b2_folder_prefix (str): Target prefix (folder) in B2. Should end with '/'\n",
    "                                 if not empty.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the overall process attempted execution, False if setup failed.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Starting B2 sync process for local folder: {local_folder_path}\")\n",
    "    logging.info(f\"Target B2 prefix: '{b2_folder_prefix}'\")\n",
    "\n",
    "    # --- Step 1: Validate Local Folder ---\n",
    "    if not local_folder_path.is_dir():\n",
    "        logging.error(f\"Error: Local folder not found or is not a directory: {local_folder_path}\")\n",
    "        return False\n",
    "    logging.info(f\"Local folder confirmed: {local_folder_path}\")\n",
    "\n",
    "    # --- Step 2: Get B2 Credentials ---\n",
    "    required_vars = [\"B2_ACCESS_KEY_ID\", \"B2_SECRET_ACCESS_KEY\", \"B2_BUCKET_NAME\"]\n",
    "    key_id = os.getenv(\"B2_ACCESS_KEY_ID\")\n",
    "    application_key = os.getenv(\"B2_SECRET_ACCESS_KEY\")\n",
    "    bucket_name = os.getenv(\"B2_BUCKET_NAME\")\n",
    "\n",
    "    if not all([key_id, application_key, bucket_name]):\n",
    "        missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "        logging.error(f\"Error: Missing required B2 configuration from .env file: {', '.join(missing_vars)}\")\n",
    "        return False\n",
    "    logging.info(\"B2 credentials loaded successfully from .env file.\")\n",
    "\n",
    "    # Initialize lists to store file names for the final report\n",
    "    uploaded_files = []\n",
    "    skipped_files = []\n",
    "    failed_files = []\n",
    "    local_files_processed = 0\n",
    "\n",
    "    try:\n",
    "        # --- Step 3: Initialize B2 API and Connect ---\n",
    "        logging.info(\"Initializing B2 API connection...\")\n",
    "        info = InMemoryAccountInfo()\n",
    "        b2_api = B2Api(info)\n",
    "        logging.info(\"Authorizing B2 account...\")\n",
    "        b2_api.authorize_account(\"production\", key_id, application_key)\n",
    "        logging.info(\"Successfully authorized B2 account.\")\n",
    "        logging.info(f\"Connecting to bucket: {bucket_name}...\")\n",
    "        bucket = b2_api.get_bucket_by_name(bucket_name)\n",
    "        logging.info(f\"Successfully connected to bucket: {bucket_name}\")\n",
    "\n",
    "        # --- Step 4: Get List of Existing Files in B2 Target Prefix ---\n",
    "        logging.info(f\"Checking for existing files in B2 bucket '{bucket_name}' under prefix '{b2_folder_prefix}'...\")\n",
    "        existing_b2_files = set()\n",
    "        try:\n",
    "            # List files only within the specified prefix, not recursively deeper\n",
    "            # The generator yields FileVersionInfo objects\n",
    "            # If the prefix doesn't exist or is empty, bucket.ls() might raise an exception\n",
    "            # (like FileNotPresent, now caught by the general Exception below) or yield nothing.\n",
    "            items_listed = 0\n",
    "            for file_info, _ in bucket.ls(folder_to_list=b2_folder_prefix or None, recursive=False, latest_only=True):\n",
    "                 items_listed += 1\n",
    "                 relative_name = file_info.file_name\n",
    "                 if b2_folder_prefix and relative_name.startswith(b2_folder_prefix):\n",
    "                     relative_name = relative_name[len(b2_folder_prefix):]\n",
    "                 \n",
    "# Explicitly check if relative_name is a non-empty string before using string methods\n",
    "            if relative_name is not None and relative_name != \"\" and not relative_name.endswith('/'):\n",
    "                existing_b2_files.add(relative_name)\n",
    "            elif relative_name is None:\n",
    "            # Log if we find an entry with no name - this shouldn't normally happen for files\n",
    "                logging.warning(f\"Found an item in B2 listing with a None file name: {file_info}\")\n",
    "            # Implicitly ignores empty strings \"\" and names ending with \"/\" (folder markers)\n",
    "\n",
    "            if items_listed == 0:\n",
    "                 logging.info(\"B2 prefix/folder appears empty or does not contain files.\")\n",
    "            logging.info(f\"Found {len(existing_b2_files)} existing files in B2 target location.\")\n",
    "\n",
    "        # Removed specific FileNotPresent handler.\n",
    "        # General Exception will now catch errors during B2 listing.\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error listing files in B2 bucket (prefix: '{b2_folder_prefix}'): {e}\")\n",
    "            # Decide if this is critical. If listing fails, we cannot accurately skip.\n",
    "            # For safety, let's treat failure to list as critical.\n",
    "            logging.error(\"Cannot reliably determine existing files. Aborting sync.\")\n",
    "            return False # Cannot proceed without knowing existing files\n",
    "\n",
    "        # --- Step 5: Iterate Through Local Files and Upload/Skip ---\n",
    "        logging.info(f\"Scanning local folder for files: {local_folder_path}\")\n",
    "        for local_item in local_folder_path.iterdir():\n",
    "            if local_item.is_file():\n",
    "                local_files_processed += 1\n",
    "                local_file_name = local_item.name\n",
    "                target_b2_file_name = f\"{b2_folder_prefix}{local_file_name}\"\n",
    "\n",
    "                if local_file_name in existing_b2_files:\n",
    "                    logging.info(f\"Skipping: '{local_file_name}' already exists in B2 as '{target_b2_file_name}'.\")\n",
    "                    skipped_files.append(local_file_name) # Add to skipped list\n",
    "                else:\n",
    "                    logging.info(f\"Uploading: '{local_file_name}' to B2 as '{target_b2_file_name}'...\")\n",
    "                    try:\n",
    "                        uploaded_file_info = bucket.upload_local_file(\n",
    "                            local_file=str(local_item),\n",
    "                            file_name=target_b2_file_name\n",
    "                        )\n",
    "                        logging.debug(f\"Successfully uploaded {local_file_name} (ID: {uploaded_file_info.id_})\")\n",
    "                        uploaded_files.append(local_file_name) # Add to uploaded list\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Failed to upload '{local_file_name}': {e}\")\n",
    "                        failed_files.append(local_file_name) # Add to failed list\n",
    "\n",
    "        # --- Step 6: Print Final Summary Report ---\n",
    "        logging.info(\"=\" * 50)\n",
    "        logging.info(\"              Sync Process Summary Report\")\n",
    "        logging.info(\"=\" * 50)\n",
    "        logging.info(f\"Local Source Folder: {local_folder_path}\")\n",
    "        logging.info(f\"Target B2 Bucket: {bucket_name}\")\n",
    "        logging.info(f\"Target B2 Prefix: '{b2_folder_prefix}'\")\n",
    "        logging.info(f\"\\nTotal Local Files Processed: {local_files_processed}\")\n",
    "        logging.info(\"-\" * 50)\n",
    "\n",
    "        # Print Uploaded Files\n",
    "        logging.info(f\"Files Uploaded Successfully ({len(uploaded_files)}):\")\n",
    "        if uploaded_files:\n",
    "            for filename in sorted(uploaded_files):\n",
    "                logging.info(f\"  - {filename}\")\n",
    "        else:\n",
    "            logging.info(\"  (None)\")\n",
    "        logging.info(\"-\" * 50)\n",
    "\n",
    "        # Print Skipped Files\n",
    "        logging.info(f\"Files Skipped - Already Exist in B2 ({len(skipped_files)}):\")\n",
    "        if skipped_files:\n",
    "            for filename in sorted(skipped_files):\n",
    "                logging.info(f\"  - {filename}\")\n",
    "        else:\n",
    "            logging.info(\"  (None)\")\n",
    "        logging.info(\"-\" * 50)\n",
    "\n",
    "        # Print Failed Files\n",
    "        logging.info(f\"Files Failed to Upload ({len(failed_files)}):\")\n",
    "        if failed_files:\n",
    "            for filename in sorted(failed_files):\n",
    "                logging.info(f\"  - {filename}\")\n",
    "        else:\n",
    "            logging.info(\"  (None)\")\n",
    "        logging.info(\"=\" * 50)\n",
    "\n",
    "        # Store failure count for exit status determination below\n",
    "        # We need to access this *outside* the main try...except block\n",
    "        global script_failed_file_count # Make count accessible outside function scope if needed by main block\n",
    "        script_failed_file_count = len(failed_files)\n",
    "\n",
    "        return True # Indicate the sync process logic completed execution\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"A critical error occurred during the B2 sync process: {e}\")\n",
    "        logging.exception(\"Detailed traceback:\")\n",
    "        script_failed_file_count = -1 # Indicate failure occurred before summary could be generated\n",
    "        return False # Indicate failure before completing the sync logic\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "script_failed_file_count = -1 # Initialize globally to track failures\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"=== B2 Folder Sync Script (.env, skip existing, detailed report) Starting ===\")\n",
    "\n",
    "    local_folder = Path(LOCAL_FOLDER_PATH)\n",
    "    b2_prefix = str(B2_FOLDER_PREFIX)\n",
    "\n",
    "    if b2_prefix and not b2_prefix.endswith('/'):\n",
    "        logging.warning(f\"B2 folder prefix '{b2_prefix}' did not end with '/'. Appending it.\")\n",
    "        b2_prefix += '/'\n",
    "\n",
    "    # Execute the sync function\n",
    "    process_completed = sync_folder_to_b2(local_folder, b2_prefix)\n",
    "\n",
    "    # Determine final exit status based on whether the process ran and if failures occurred\n",
    "    if process_completed and script_failed_file_count == 0:\n",
    "        logging.info(\"Script finished successfully.\")\n",
    "    elif process_completed and script_failed_file_count > 0:\n",
    "        logging.warning(f\"Script finished, but {script_failed_file_count} file(s) failed to upload. See report above.\")\n",
    "        exit(1) # Exit with error code if failures occurred\n",
    "    else:\n",
    "        # This case handles failures during setup or B2 connection before processing files\n",
    "        logging.error(\"Script failed during setup or a major B2 operation (like listing files). Please check logs.\")\n",
    "        exit(1) # Exit with error code\n",
    "\n",
    "    logging.info(\"=== Script Execution Complete ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac733a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
